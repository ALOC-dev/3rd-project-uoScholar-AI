from fastapi import FastAPI
from pydantic import BaseModel
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
import mysql.connector
import os
import json
import re

# 1. í™˜ê²½ ë³€ìˆ˜ ë° GPT ì„¤ì •
load_dotenv()
os.environ["OPENAI_API_KEY"] = 
llm = ChatOpenAI(model="gpt-4o", temperature=0.2)

# 2. FastAPI ì•± ìƒì„±
app = FastAPI()

# 3. ìš”ì²­ ë°”ë”” ëª¨ë¸
class Question(BaseModel):
    question: str

# 4. MySQL ì—°ê²° í•¨ìˆ˜
def get_connection():
    return mysql.connector.connect(
        host="uoscholar.cdkke4m4o6zb.ap-northeast-2.rds.amazonaws.com",
        user="admin",
        password="dongha1005!",
        database="uoscholar_db",
        port=3306
    )

# 5. GPT í”„ë¡¬í”„íŠ¸ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_keywords(user_input: str) -> dict:
    prompt = f"""
ë„ˆëŠ” ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ì´í•´í•˜ê³ , ë‹¤ìŒ ì„¸ ê°€ì§€ í•­ëª©ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í‚¤ì›Œë“œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì•¼ í•´.

1. "title_keywords": ê³µì§€ ì œëª©ì— ë“¤ì–´ê°ˆ ë§Œí•œ **êµ¬ì²´ì ì´ê³  í•µì‹¬ì ì¸ ë‹¨ì–´**ë§Œ (ì˜ˆ: "ì¥í•™ê¸ˆ", "íœ´í•™", "ë“±ë¡ê¸ˆ")  
   - "ê³µì§€", "ì•ˆë‚´", "ì‹ ì²­" ê°™ì€ **ë²”ìš© ë‹¨ì–´ëŠ” ì œì™¸í•´**  
   - **1~2ê°œë§Œ** ì¶”ì¶œí•´
2. "writer_keywords": ê³µì§€ë¥¼ ì‘ì„±í–ˆì„ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ë¶€ì„œ, í˜¹ì€ í•™ê³¼ 
3. "year": íŠ¹ì • í•™ë…„ë„ë‚˜ ì—°ë„ê°€ ëª…ì‹œëœ ê²½ìš° (ìˆ«ì), ì—†ìœ¼ë©´ null

[ì‚¬ìš©ì ì§ˆë¬¸]
"{user_input}"

[ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]
{{
  "title_keywords": ["ì¥í•™ê¸ˆ"],
  "writer_keywords": ["í•™ìƒì²˜"],
  "year": 2024
}}

ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•´ì¤˜. ```json ê°™ì€ ë§ˆí¬ë‹¤ìš´ë„ ì œê±°í•´ì¤˜.
"""
    response = llm.invoke(prompt)
    content = response.content.strip()
    content = re.sub(r"```json|```", "", content).strip()

    try:
        return json.loads(content)
    except Exception as e:
        print("âŒ GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:", e)
        print("GPT ì‘ë‹µ ë‚´ìš©:\n", content)
        return {"title_keywords": [], "writer_keywords": [], "year": None}

# DBì—ì„œ ê³µì§€ ê²€ìƒ‰ (ì—¬ëŸ¬ í‚¤ì›Œë“œ OR ì¡°ê±´ + ë¶€ì„œ LIKE)
def search_notices(title_keywords, year, department_keyword):
    try:
        conn = get_connection()
        cursor = conn.cursor(dictionary=True)

        title_conditions = " OR ".join(["title LIKE %s" for _ in title_keywords])
        query = f"""
        SELECT * FROM notice
        WHERE ({title_conditions})
          AND YEAR(posted_date) = %s
          AND department LIKE %s
        LIMIT 10;
        """
        params = [f"%{kw}%" for kw in title_keywords] + [year, f"%{department_keyword}%"]
        cursor.execute(query, params)
        rows = cursor.fetchall()
        cursor.close()
        conn.close()
        return rows

    except Exception as e:
        print("âŒ DB ì¿¼ë¦¬ ì—ëŸ¬:", e)
        return []
    
# 7. GPTê°€ DB ê²°ê³¼ë¡œ ìì—°ì–´ ë‹µë³€ ìƒì„±
def generate_answer(question: str, search_results: list) -> str:
    if not search_results:
        return "ìš”ì²­í•˜ì‹  ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ê³µì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    summarized = "\n\n".join(
        f"- {row['posted_date']} | {row['department']} | {row['title']}\n  ğŸ“ ë§í¬: {row['link']}"
        for row in search_results
    )

    prompt = f"""
[ì‚¬ìš©ì ì§ˆë¬¸]
{question}

[ê´€ë ¨ ê³µì§€ ëª©ë¡]
{summarized}

ìœ„ ê³µì§€ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½ëœ ë‹µë³€ì„ í•´ì¤˜.
ë„ˆëŠ” ì¹œì ˆí•˜ê³  ì •í™•í•œ ì±—ë´‡ì´ì•¼. ê³µì§€ ì œëª©ê³¼ ë‚ ì§œ, ë¶€ì„œë¥¼ ì ì ˆíˆ ì°¸ê³ í•´ì„œ í‚¤ì›Œë“œê°€ ë“¤ì–´ê°€ìˆëŠ” í•­ëª©ë“¤ì„ ì°¾ì•„ì„œ ìš”ì•½í•´ì¤˜.
"""
    response = llm.invoke(prompt)
    return response.content.strip()

# 8. ë©”ì¸ API ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze_question")
def analyze_question(q: Question):
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = extract_keywords(q.question)

    # DB ê²€ìƒ‰
    title_keywords = keywords["title_keywords"]
    dept_keyword = keywords["writer_keywords"][0] if keywords["writer_keywords"] else ""
    year = keywords["year"] or 2024
    results = search_notices(title_keywords, year, dept_keyword)

    # GPT ë‹µë³€ ìƒì„±
    gpt_answer = generate_answer(q.question, results)

    return {
        "extracted_keywords": keywords,
        "search_results": results,
        "gpt_answer": gpt_answer
    }
