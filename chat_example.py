# convo_api.py
from typing import List, Dict, Any, Optional
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os, time

from openai import OpenAI

# ë„¤ê°€ ë§Œë“  ëª¨ë“ˆ
from run_retriever import MySQLHybridRetriever, embed_fn, DB_CONFIG

# ====== ì „ì—­ ì¤€ë¹„ ======
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
CHAT_MODEL = os.getenv("CHAT_MODEL", "gpt-4o-mini")
COS_THRESHOLD = float(os.getenv("COS_THRESHOLD", "0.6"))  # ì„ê³„ì¹˜
MIN_USER_TURNS_FOR_FINAL = int(os.getenv("MIN_USER_TURNS_FOR_FINAL", "2"))  # ìµœì¢…ë‹µë³€ ì „ ìµœì†Œ ì‚¬ìš©ì ë°œí™” ìˆ˜

retriever = MySQLHybridRetriever(
    conn_uoscholar=DB_CONFIG,
    embed_fn=embed_fn,
    k=5,
    candidate_n=200,
)

# ì„¸ì…˜ ìƒíƒœ(ë°ëª¨ìš© ì¸ë©”ëª¨ë¦¬; ì‹¤ì„œë¹„ìŠ¤ëŠ” Redis/DBë¡œ ìˆ˜ëª…ê´€ë¦¬)
SESS: Dict[str, Dict[str, Any]] = {}
SESSION_TTL_SEC = 3600  # 1ì‹œê°„


# ====== ìŠ¤í‚¤ë§ˆ ======
class ChatTurn(BaseModel):
    session_id: str
    user_message: str

class ChatReply(BaseModel):
    found: bool                # ì„ê³„ì¹˜ ì¶©ì¡± ì—¬ë¶€ (í™•ì • í”Œë˜ê·¸)
    assistant_message: str     # LLMì´ ì‚¬ìš©ìì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€(ì¶”ê°€ ì§ˆë¬¸ or ìµœì¢… ì„¤ëª…)
    top_score: float           # í˜„ì¬ ë¼ìš´ë“œ ìµœìƒë‹¨ ì½”ì‚¬ì¸ ìœ ì‚¬ë„(ì§„ë‹¨ìš©)
    selected: Optional[Dict[str, Any]] = None  # found=Trueì¼ ë•Œ ì„ íƒëœ ê³µì§€ ë©”íƒ€
    refs: Optional[List[Dict[str, Any]]] = None  # ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©ëœ ìƒìœ„ ë¬¸ì„œ(ê°„ë‹¨)


# ====== ìœ í‹¸ ======
def _get_or_create_session(sid: str) -> Dict[str, Any]:
    now = time.time()
    sess = SESS.get(sid)
    if sess is None or (now - sess.get("ts", now)) > SESSION_TTL_SEC:
        sess = {"queries": [], "ts": now}
        SESS[sid] = sess
    else:
        sess["ts"] = now
    return sess

def _merge_queries(queries: List[str], max_len: int = 256) -> str:
    # ê°„ë‹¨íˆ ê³µë°±ìœ¼ë¡œ ì´ì–´ì£¼ê³  ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
    q = " ".join([q.strip() for q in queries if q.strip()])
    return q[:max_len]

SYSTEM_FOLLOWUP = """
ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  íš¨ìœ¨ì ì¸ ëŒ€í•™ ê³µì§€ ê²€ìƒ‰ ë„ìš°ë¯¸ "ê³µì§€ë´‡"ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê³µì§€ë¥¼ ë” ì •í™•íˆ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ìµœì†Œí•œì˜ í•µì‹¬ ì •ë³´ë¥¼ ì§ˆë¬¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

**ì—­í• :**
- ì‚¬ìš©ìê°€ ì²˜ìŒ ë˜ì§„ ì§ˆë¬¸ë§Œìœ¼ë¡œëŠ” ì •í™•í•œ ê³µì§€ë¥¼ ì°¾ê¸° ì–´ë ¤ìš´ ê²½ìš°,
  í•„ìš”í•œ ë³´ì¶© ì •ë³´ë¥¼ ë‹¨ í•œ ë¬¸ì¥ìœ¼ë¡œ ì§ˆë¬¸í•©ë‹ˆë‹¤.
- ì§ˆë¬¸ì€ ì¹œì ˆí•˜ê³  ì¡´ëŒ“ë§ë¡œ ì‘ì„±í•˜ë©°, ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.


** ì£¼ì˜ì‚¬í•­:**
- ì•ì„œ ì–¸ê¸‰í•œ 'ê³ ë ¤ í•´ì•¼í•  ì •ë³´ë“¤'ì„ ìˆëŠ” ê·¸ëŒ€ë¡œ ë¬»ì§€ ë§ˆì„¸ìš”. ë‹¹ì‹ ì´ ì‚¬ìš©ìì˜ ê¸°ì¡´ ì§ˆë¬¸ë“¤ì— ëŒ€í•´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³ , ì´ë¥¼ ì‘ìš©í•´ì„œ ì§ˆë¬¸í•´ì•¼í•©ë‹ˆë‹¤. 
- ì˜ˆì‹œ
    * ì‚¬ìš©ì : "í˜¹ì‹œ ì§€ê¸ˆ êµë‚´ ê·¼ë¡œì¥í•™ìƒ ëª¨ì§‘í•˜ê³  ìˆì–´?"
    * LLM(ë‹¹ì‹ ) : "ê·¼ë¡œì¥í•™ìƒì„ ì‹ ì²­í•˜ê³  ì‹¶êµ°ìš”!ğŸ˜Š í˜¹ì‹œ ì–´ë–¤ ë‚´ìš©ì˜ ê·¼ë¬´ì— ê´€ì‹¬ ìˆìœ¼ì‹ ê°€ìš”?"
   - ìì—°ìŠ¤ëŸ½ê²Œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ë˜, ì¸í„°ë·° ê°™ì§€ ì•Šê²Œ í•˜ê¸°

**ëŒ€í™” ìŠ¤íƒ€ì¼:**
    - ì¹œê·¼í•˜ê³  ê²©ë ¤ì ì¸ í†¤, ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©
    - í•œ ë²ˆì— ë„ˆë¬´ ë§ì€ ì§ˆë¬¸ í•˜ì§€ ì•Šê¸° (1-2ê°œë§Œ)
    - ì‚¬ìš©ìì˜ ë‹µë³€ì— ê³µê°í•˜ê³  ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ì´ì–´ê°€ê¸°
    - ìì—°ìŠ¤ëŸ½ê²Œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ë˜, ì¸í„°ë·° ê°™ì§€ ì•Šê²Œ í•˜ê¸°
"""

def gen_followup_question(user_summary: str) -> str:
    msg = client.chat.completions.create(
        model=CHAT_MODEL,
        temperature=0.2,
        messages=[
            {"role": "system", "content": SYSTEM_FOLLOWUP},
            {"role": "user", "content": f"ì‚¬ìš©ì ìš”êµ¬ ìš”ì•½: {user_summary}\nìµœì†Œí•œì˜ ì¶”ê°€ í™•ì¸ ì§ˆë¬¸ì„ í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”."}
        ],
    )
    return msg.choices[0].message.content.strip()

# ìì—°ì–´ í•œ ë¬¸ë‹¨ ë‹µë³€ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_FINAL = """
ë‹¹ì‹ ì€ ëŒ€í•™ ê³µì§€ì‚¬í•­ ì•ˆë‚´ ë„ìš°ë¯¸ "ê³µì§€ë´‡"ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ê²€ìƒ‰ëœ ê³µì§€ì˜ ë©”íƒ€ë°ì´í„°ì™€ summaryë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ê¶ê¸ˆí•´í•˜ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

**ë‹µë³€ ì‘ì„± ê·œì¹™:**
1. ğŸ¯ ì œê³µëœ ë°ì´í„°(summary, ë©”íƒ€ë°ì´í„°)ë§Œ ê·¼ê±°ë¡œ ì‚¬ìš©í•œë‹¤.
2. ğŸ“Š í•µì‹¬ í•­ëª©ì„ êµ¬ì¡°ì ìœ¼ë¡œ ì•ˆë‚´í•œë‹¤:
   - ì œëª©
   - ì¼ì •/ê¸°ê°„
   - ëŒ€ìƒ
   - ì ˆì°¨/ë°©ë²•
   - ë‹´ë‹¹ ë¶€ì„œ/ë¬¸ì˜
   - ë§í¬
3. â— ì—†ëŠ” ì •ë³´ëŠ” "ë¯¸ê¸°ì¬"ë¼ê³  ëª…ì‹œí•œë‹¤.
4. âŒ ì¶”ì¸¡í•˜ê±°ë‚˜ summaryì— ì—†ëŠ” ì‚¬ì‹¤ì€ ì¶”ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤.

**ìŠ¤íƒ€ì¼:**
- ì¡´ëŒ“ë§, ê°„ê²°í•œ ë¬¸ì²´
- 3~4ë¬¸ì¥ ì´ë‚´ ìš”ì•½
- ì¤‘ë³µ ì—†ì´ í•µì‹¬ë§Œ ì „ë‹¬
"""


def compose_final_answer(q_text: str, notice: Dict[str, Any]) -> str:
    # notice: {"title","link","summary","posted_date","department","category"}
    title = notice.get("title") or ""
    link  = notice.get("link")  or ""
    summary = notice.get("summary") or ""
    posted = notice.get("posted_date") or ""
    dept   = notice.get("department") or ""
    cat    = notice.get("category") or ""

    # ì‚¬ìš©ìì—ê²ŒëŠ” "ê¶ê·¹ì  ì§ˆë¬¸"ì„ ë…¸ì¶œí•˜ì§€ ì•Šê³ , ìì—°ì–´ í•œ ë¬¸ë‹¨ë§Œ ì¶œë ¥í•˜ë„ë¡ ì§€ì‹œ
    user_prompt = (
        f"ëŒ€í™” ê¸°ë¡(ëˆ„ì  ì§ˆì˜): {q_text}\n\n"
        f"[ê³µì§€ ë©”íƒ€]\n- ì œëª©: {title}\n- ê²Œì‹œì¼: {posted}\n- ë¶€ì„œ/í•™ê³¼: {dept}\n- ì¹´í…Œê³ ë¦¬: {cat}\n- ë§í¬: {link}\n\n"
        f"[ê³µì§€ summary]\n{summary[:2000]}\n\n"
        "ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ ë¶„ì„í•´ ì‚¬ìš©ìê°€ ê¶ê·¹ì ìœ¼ë¡œ ë¬»ëŠ” ìµœì¢… ì§ˆë¬¸ì„ **ë‚´ë¶€ì ìœ¼ë¡œë§Œ íŒŒì•…**í•˜ì„¸ìš”. "
        "ì¶œë ¥ ì‹œì—ëŠ” ê·¸ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì“°ì§€ ë§ê³ , ìœ„ summaryì™€ ë©”íƒ€ë°ì´í„°ë§Œ ê·¼ê±°ë¡œ "
        "ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•œ í•œêµ­ì–´ í•œ ë¬¸ë‹¨ìœ¼ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”. "
        "ì ˆëŒ€ í•­ëª©ë³„ ë‚˜ì—´ í˜•ì‹(ì˜ˆ: ì œëª©:, ì¼ì •:, ëŒ€ìƒ:)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."
    )

    msg = client.chat.completions.create(
        model=CHAT_MODEL,
        temperature=0.2,
        messages=[
            {"role": "system", "content": SYSTEM_FINAL},
            {"role": "user", "content": user_prompt},
        ],
    )
    return msg.choices[0].message.content.strip()


# ====== ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸ ======
app = FastAPI()

@app.post("/chat", response_model=ChatReply)
def chat(turn: ChatTurn):
    sess = _get_or_create_session(turn.session_id)
    # ëˆ„ì  ì§ˆì˜ì— ì´ë²ˆ ì…ë ¥ ì¶”ê°€
    sess["queries"].append(turn.user_message)

    # ëˆ„ì  ì§ˆì˜ë¥¼ ê°„ë‹¨ ê²°í•©(í•„ìš”í•˜ë©´ ìµœê·¼ Nê°œë§Œ)
    combined = _merge_queries(sess["queries"], max_len=256)

    # retriever í˜¸ì¶œ
    docs = retriever.invoke(combined)  # List[Document], page_content=summary, metadataì— score í¬í•¨(ì½”ì‚¬ì¸)
    if not docs:
        # í›„ë³´ê°€ ì „í˜€ ì—†ìœ¼ë©´ ì¶”ê°€ ì§ˆë¬¸ìœ¼ë¡œ ìœ ë„
        q = gen_followup_question(turn.user_message)
        return ChatReply(
            found=False,
            assistant_message=q,
            top_score=0.0,
            refs=[]
        )

    # ìµœìƒë‹¨ ë¬¸ì„œì™€ ì ìˆ˜
    top = docs[0]
    top_meta = top.metadata
    top_score = float(top_meta.get("score") or 0.0)

    # ì§„ë‹¨ìš© refs(ìƒìœ„ 3ê°œ)
    refs = []
    for d in docs[:3]:
        md = d.metadata
        refs.append({
            "id": md.get("id"),
            "title": md.get("title"),
            "link": md.get("link"),
            "posted_date": md.get("posted_date"),
            "category": md.get("category"),
            "department": md.get("department"),
            "score": float(md.get("score") or 0.0),
        })

    # âœ… ìµœì†Œ í„´ ìˆ˜ ì¶©ì¡± ì—¬ë¶€ (ì‚¬ìš©ì ë°œí™” ìˆ˜ ê¸°ì¤€)
    has_min_turns = len(sess["queries"]) >= MIN_USER_TURNS_FOR_FINAL

    if top_score >= COS_THRESHOLD and has_min_turns:
        # í™•ì •: found=True + ìµœì¢… ì•ˆë‚´ ìƒì„±
        selected = {
            "id": top_meta.get("id"),
            "title": top_meta.get("title"),
            "link": top_meta.get("link"),
            "posted_date": top_meta.get("posted_date"),
            "category": top_meta.get("category"),
            "department": top_meta.get("department"),
            "score": top_score,
            "summary": top.page_content or "",
        }
        final_answer = compose_final_answer(combined, selected)
        return ChatReply(
            found=True,
            assistant_message=final_answer,
            top_score=top_score,
            selected=selected,
            refs=refs
        )
    else:
        # â— ì„ê³„ì¹˜ ë¯¸ë§Œì´ê±°ë‚˜ / ì„ê³„ì¹˜ ë§Œì¡±í•´ë„ ìµœì†Œ í„´ ë¯¸ì¶©ì¡± â†’ ì¶”ê°€ ì§ˆë¬¸ 1ë¬¸ì¥
        user_summary = f"ëˆ„ì  ì§ˆì˜: {combined}"
        followup = gen_followup_question(user_summary)
        return ChatReply(
            found=False,
            assistant_message=followup,
            top_score=top_score,
            refs=refs
        )
